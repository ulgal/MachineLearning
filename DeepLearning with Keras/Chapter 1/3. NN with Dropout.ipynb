{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.datasets import mnist\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# basic Neural Network\n",
    "\n",
    "# 재현을 위한 설정\n",
    "np.random.seed(1671)\n",
    "\n",
    "# 네트워크와 학습 설정\n",
    "NB_EPOCH = 250\n",
    "BATCH_SIZE = 128\n",
    "VERBOSE = 1\n",
    "NB_CLASSES = 10 # 출력 범주, 숫자의 종류[0:9]\n",
    "OPTIMIZER = SGD() # SGD optimizer\n",
    "N_HIDDEN = 128\n",
    "VALIDATION_SPLIT = 0.2 # 학습 데이터 중 얼마나 검증 데이터로 할당할 지 지정\n",
    "DROPOUT = 0.3\n",
    "# 데이터: 무작위로 섞고, 학습 데이터와 테스트 데이터로 나눔\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# X_train은 6만개의 행으로 구성, 28*28개의 값을 가지므로 60000*784 형태로 변환\n",
    "RESHAPED = 784\n",
    "X_train = X_train.reshape(60000, RESHAPED)\n",
    "X_test = X_test.reshape(10000, RESHAPED)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "# Normalization\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "# 범주 벡터를 이진 범주 행렬로 변환\n",
    "Y_train = np_utils.to_categorical(y_train, NB_CLASSES)\n",
    "Y_test = np_utils.to_categorical(y_test, NB_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0813 17:00:58.652600  3032 deprecation_wrapper.py:119] From C:\\Users\\user\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0813 17:00:58.661600  3032 deprecation_wrapper.py:119] From C:\\Users\\user\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0813 17:00:58.673600  3032 deprecation_wrapper.py:119] From C:\\Users\\user\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0813 17:00:58.699600  3032 deprecation_wrapper.py:119] From C:\\Users\\user\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0813 17:00:58.722600  3032 deprecation.py:506] From C:\\Users\\user\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1290      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 118,282\n",
      "Trainable params: 118,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 10개 출력\n",
    "# 최종 단계는 softmax\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(N_HIDDEN, input_shape=(RESHAPED, )))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(DROPOUT))\n",
    "model.add(Dense(N_HIDDEN))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(DROPOUT))\n",
    "model.add(Dense(NB_CLASSES))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0813 17:00:58.858600  3032 deprecation_wrapper.py:119] From C:\\Users\\user\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0813 17:00:58.879600  3032 deprecation_wrapper.py:119] From C:\\Users\\user\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss = 'categorical_crossentropy', optimizer=OPTIMIZER, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0813 17:00:59.034600  3032 deprecation.py:323] From C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/250\n",
      "48000/48000 [==============================] - 3s 53us/step - loss: 1.7404 - acc: 0.4539 - val_loss: 0.9292 - val_acc: 0.8125\n",
      "Epoch 2/250\n",
      "48000/48000 [==============================] - 2s 48us/step - loss: 0.9231 - acc: 0.7230 - val_loss: 0.5400 - val_acc: 0.8654\n",
      "Epoch 3/250\n",
      "48000/48000 [==============================] - 2s 45us/step - loss: 0.6935 - acc: 0.7881 - val_loss: 0.4297 - val_acc: 0.8884\n",
      "Epoch 4/250\n",
      "48000/48000 [==============================] - 2s 45us/step - loss: 0.5947 - acc: 0.8209 - val_loss: 0.3790 - val_acc: 0.8977\n",
      "Epoch 5/250\n",
      "48000/48000 [==============================] - 2s 46us/step - loss: 0.5347 - acc: 0.8394 - val_loss: 0.3456 - val_acc: 0.9042\n",
      "Epoch 6/250\n",
      "48000/48000 [==============================] - 2s 47us/step - loss: 0.4976 - acc: 0.8523 - val_loss: 0.3232 - val_acc: 0.9106\n",
      "Epoch 7/250\n",
      "48000/48000 [==============================] - 2s 47us/step - loss: 0.4616 - acc: 0.8628 - val_loss: 0.3048 - val_acc: 0.9130\n",
      "Epoch 8/250\n",
      "48000/48000 [==============================] - 2s 45us/step - loss: 0.4386 - acc: 0.8689 - val_loss: 0.2896 - val_acc: 0.9173\n",
      "Epoch 9/250\n",
      "48000/48000 [==============================] - 2s 46us/step - loss: 0.4181 - acc: 0.8761 - val_loss: 0.2776 - val_acc: 0.9198\n",
      "Epoch 10/250\n",
      "48000/48000 [==============================] - 2s 44us/step - loss: 0.3990 - acc: 0.8839 - val_loss: 0.2657 - val_acc: 0.9233\n",
      "Epoch 11/250\n",
      "48000/48000 [==============================] - 2s 44us/step - loss: 0.3819 - acc: 0.8875 - val_loss: 0.2551 - val_acc: 0.9257\n",
      "Epoch 12/250\n",
      "48000/48000 [==============================] - 2s 46us/step - loss: 0.3688 - acc: 0.8920 - val_loss: 0.2466 - val_acc: 0.9283\n",
      "Epoch 13/250\n",
      "48000/48000 [==============================] - 2s 46us/step - loss: 0.3571 - acc: 0.8942 - val_loss: 0.2388 - val_acc: 0.9302\n",
      "Epoch 14/250\n",
      "48000/48000 [==============================] - 2s 45us/step - loss: 0.3466 - acc: 0.8991 - val_loss: 0.2320 - val_acc: 0.9322\n",
      "Epoch 15/250\n",
      "48000/48000 [==============================] - 2s 46us/step - loss: 0.3359 - acc: 0.9015 - val_loss: 0.2261 - val_acc: 0.9339\n",
      "Epoch 16/250\n",
      "48000/48000 [==============================] - 2s 45us/step - loss: 0.3244 - acc: 0.9054 - val_loss: 0.2180 - val_acc: 0.9352\n",
      "Epoch 17/250\n",
      "48000/48000 [==============================] - 2s 44us/step - loss: 0.3142 - acc: 0.9085 - val_loss: 0.2122 - val_acc: 0.9376\n",
      "Epoch 18/250\n",
      "48000/48000 [==============================] - 2s 44us/step - loss: 0.3103 - acc: 0.9095 - val_loss: 0.2075 - val_acc: 0.9390\n",
      "Epoch 19/250\n",
      "48000/48000 [==============================] - 2s 44us/step - loss: 0.3019 - acc: 0.9118 - val_loss: 0.2018 - val_acc: 0.9408\n",
      "Epoch 20/250\n",
      "48000/48000 [==============================] - 2s 45us/step - loss: 0.2931 - acc: 0.9131 - val_loss: 0.1974 - val_acc: 0.9421\n",
      "Epoch 21/250\n",
      "48000/48000 [==============================] - 2s 44us/step - loss: 0.2866 - acc: 0.9171 - val_loss: 0.1920 - val_acc: 0.9437\n",
      "Epoch 22/250\n",
      "48000/48000 [==============================] - 2s 43us/step - loss: 0.2789 - acc: 0.9171 - val_loss: 0.1879 - val_acc: 0.9447\n",
      "Epoch 23/250\n",
      "48000/48000 [==============================] - 2s 44us/step - loss: 0.2730 - acc: 0.9200 - val_loss: 0.1841 - val_acc: 0.9464\n",
      "Epoch 24/250\n",
      "48000/48000 [==============================] - 2s 44us/step - loss: 0.2686 - acc: 0.9211 - val_loss: 0.1811 - val_acc: 0.9464\n",
      "Epoch 25/250\n",
      "48000/48000 [==============================] - 2s 44us/step - loss: 0.2618 - acc: 0.9233 - val_loss: 0.1770 - val_acc: 0.9477\n",
      "Epoch 26/250\n",
      "48000/48000 [==============================] - 2s 43us/step - loss: 0.2584 - acc: 0.9250 - val_loss: 0.1736 - val_acc: 0.9488\n",
      "Epoch 27/250\n",
      "48000/48000 [==============================] - 2s 43us/step - loss: 0.2539 - acc: 0.9254 - val_loss: 0.1706 - val_acc: 0.9495\n",
      "Epoch 28/250\n",
      "48000/48000 [==============================] - 2s 44us/step - loss: 0.2453 - acc: 0.9277 - val_loss: 0.1677 - val_acc: 0.9503\n",
      "Epoch 29/250\n",
      "48000/48000 [==============================] - 2s 44us/step - loss: 0.2427 - acc: 0.9274 - val_loss: 0.1641 - val_acc: 0.9516\n",
      "Epoch 30/250\n",
      "48000/48000 [==============================] - 2s 45us/step - loss: 0.2397 - acc: 0.9297 - val_loss: 0.1616 - val_acc: 0.9523\n",
      "Epoch 31/250\n",
      "48000/48000 [==============================] - 2s 43us/step - loss: 0.2360 - acc: 0.9302 - val_loss: 0.1590 - val_acc: 0.9533\n",
      "Epoch 32/250\n",
      "48000/48000 [==============================] - 2s 43us/step - loss: 0.2320 - acc: 0.9306 - val_loss: 0.1568 - val_acc: 0.9545\n",
      "Epoch 33/250\n",
      "48000/48000 [==============================] - 2s 43us/step - loss: 0.2284 - acc: 0.9326 - val_loss: 0.1534 - val_acc: 0.9553\n",
      "Epoch 34/250\n",
      "48000/48000 [==============================] - 2s 43us/step - loss: 0.2257 - acc: 0.9325 - val_loss: 0.1519 - val_acc: 0.9550\n",
      "Epoch 35/250\n",
      "48000/48000 [==============================] - 2s 43us/step - loss: 0.2214 - acc: 0.9354 - val_loss: 0.1502 - val_acc: 0.9557\n",
      "Epoch 36/250\n",
      "48000/48000 [==============================] - 2s 43us/step - loss: 0.2169 - acc: 0.9354 - val_loss: 0.1485 - val_acc: 0.9563\n",
      "Epoch 37/250\n",
      "48000/48000 [==============================] - 2s 43us/step - loss: 0.2124 - acc: 0.9377 - val_loss: 0.1459 - val_acc: 0.9570\n",
      "Epoch 38/250\n",
      "48000/48000 [==============================] - 2s 42us/step - loss: 0.2122 - acc: 0.9373 - val_loss: 0.1432 - val_acc: 0.9579\n",
      "Epoch 39/250\n",
      "48000/48000 [==============================] - 2s 43us/step - loss: 0.2091 - acc: 0.9387 - val_loss: 0.1422 - val_acc: 0.9575\n",
      "Epoch 40/250\n",
      "48000/48000 [==============================] - 2s 43us/step - loss: 0.2042 - acc: 0.9392 - val_loss: 0.1411 - val_acc: 0.9580\n",
      "Epoch 41/250\n",
      "48000/48000 [==============================] - 2s 45us/step - loss: 0.2027 - acc: 0.9398 - val_loss: 0.1396 - val_acc: 0.9584\n",
      "Epoch 42/250\n",
      "48000/48000 [==============================] - 2s 42us/step - loss: 0.1985 - acc: 0.9415 - val_loss: 0.1367 - val_acc: 0.9594\n",
      "Epoch 43/250\n",
      "48000/48000 [==============================] - 2s 43us/step - loss: 0.2003 - acc: 0.9410 - val_loss: 0.1350 - val_acc: 0.9608\n",
      "Epoch 44/250\n",
      "48000/48000 [==============================] - 2s 42us/step - loss: 0.1953 - acc: 0.9422 - val_loss: 0.1338 - val_acc: 0.9606\n",
      "Epoch 45/250\n",
      "48000/48000 [==============================] - 2s 44us/step - loss: 0.1921 - acc: 0.9431 - val_loss: 0.1332 - val_acc: 0.9601\n",
      "Epoch 46/250\n",
      "48000/48000 [==============================] - 2s 42us/step - loss: 0.1901 - acc: 0.9445 - val_loss: 0.1317 - val_acc: 0.9615\n",
      "Epoch 47/250\n",
      "48000/48000 [==============================] - 2s 42us/step - loss: 0.1876 - acc: 0.9451 - val_loss: 0.1300 - val_acc: 0.9613\n",
      "Epoch 48/250\n",
      "48000/48000 [==============================] - 2s 42us/step - loss: 0.1867 - acc: 0.9442 - val_loss: 0.1301 - val_acc: 0.9618\n",
      "Epoch 49/250\n",
      "48000/48000 [==============================] - 2s 41us/step - loss: 0.1865 - acc: 0.9451 - val_loss: 0.1283 - val_acc: 0.9614\n",
      "Epoch 50/250\n",
      "48000/48000 [==============================] - 2s 42us/step - loss: 0.1803 - acc: 0.9461 - val_loss: 0.1267 - val_acc: 0.9622\n",
      "Epoch 51/250\n",
      "48000/48000 [==============================] - 2s 41us/step - loss: 0.1823 - acc: 0.9467 - val_loss: 0.1255 - val_acc: 0.9633\n",
      "Epoch 52/250\n",
      "48000/48000 [==============================] - 2s 41us/step - loss: 0.1794 - acc: 0.9460 - val_loss: 0.1245 - val_acc: 0.9632\n",
      "Epoch 53/250\n",
      "48000/48000 [==============================] - 2s 41us/step - loss: 0.1753 - acc: 0.9480 - val_loss: 0.1233 - val_acc: 0.9634\n",
      "Epoch 54/250\n",
      "48000/48000 [==============================] - 2s 42us/step - loss: 0.1738 - acc: 0.9478 - val_loss: 0.1220 - val_acc: 0.9636\n",
      "Epoch 55/250\n",
      "48000/48000 [==============================] - 2s 42us/step - loss: 0.1736 - acc: 0.9492 - val_loss: 0.1208 - val_acc: 0.9646\n",
      "Epoch 56/250\n",
      "48000/48000 [==============================] - 2s 43us/step - loss: 0.1719 - acc: 0.9485 - val_loss: 0.1208 - val_acc: 0.9639\n",
      "Epoch 57/250\n",
      "48000/48000 [==============================] - 2s 42us/step - loss: 0.1692 - acc: 0.9503 - val_loss: 0.1188 - val_acc: 0.9650\n",
      "Epoch 58/250\n",
      "48000/48000 [==============================] - 2s 41us/step - loss: 0.1663 - acc: 0.9507 - val_loss: 0.1187 - val_acc: 0.9649\n",
      "Epoch 59/250\n",
      "48000/48000 [==============================] - 2s 43us/step - loss: 0.1682 - acc: 0.9500 - val_loss: 0.1173 - val_acc: 0.9654\n",
      "Epoch 60/250\n",
      "48000/48000 [==============================] - 2s 42us/step - loss: 0.1647 - acc: 0.9514 - val_loss: 0.1166 - val_acc: 0.9652\n",
      "Epoch 61/250\n",
      "48000/48000 [==============================] - 2s 41us/step - loss: 0.1615 - acc: 0.9521 - val_loss: 0.1157 - val_acc: 0.9654\n",
      "Epoch 62/250\n",
      "48000/48000 [==============================] - 2s 41us/step - loss: 0.1592 - acc: 0.9525 - val_loss: 0.1149 - val_acc: 0.9657\n",
      "Epoch 63/250\n",
      "48000/48000 [==============================] - 2s 42us/step - loss: 0.1587 - acc: 0.9533 - val_loss: 0.1142 - val_acc: 0.9659\n",
      "Epoch 64/250\n",
      "48000/48000 [==============================] - 2s 41us/step - loss: 0.1564 - acc: 0.9531 - val_loss: 0.1126 - val_acc: 0.9667\n",
      "Epoch 65/250\n",
      "48000/48000 [==============================] - 2s 40us/step - loss: 0.1560 - acc: 0.9541 - val_loss: 0.1129 - val_acc: 0.9668\n",
      "Epoch 66/250\n",
      "48000/48000 [==============================] - 2s 43us/step - loss: 0.1572 - acc: 0.9535 - val_loss: 0.1120 - val_acc: 0.9664\n",
      "Epoch 67/250\n",
      "48000/48000 [==============================] - 2s 41us/step - loss: 0.1554 - acc: 0.9547 - val_loss: 0.1105 - val_acc: 0.9667\n",
      "Epoch 68/250\n",
      "48000/48000 [==============================] - 2s 41us/step - loss: 0.1525 - acc: 0.9544 - val_loss: 0.1103 - val_acc: 0.9673\n",
      "Epoch 69/250\n",
      "48000/48000 [==============================] - 2s 40us/step - loss: 0.1523 - acc: 0.9554 - val_loss: 0.1089 - val_acc: 0.9677\n",
      "Epoch 70/250\n",
      "48000/48000 [==============================] - 2s 42us/step - loss: 0.1502 - acc: 0.9552 - val_loss: 0.1086 - val_acc: 0.9677\n",
      "Epoch 71/250\n",
      "48000/48000 [==============================] - 2s 41us/step - loss: 0.1478 - acc: 0.9566 - val_loss: 0.1082 - val_acc: 0.9681\n",
      "Epoch 72/250\n",
      "48000/48000 [==============================] - 2s 40us/step - loss: 0.1450 - acc: 0.9567 - val_loss: 0.1073 - val_acc: 0.9685\n",
      "Epoch 73/250\n",
      "48000/48000 [==============================] - 2s 41us/step - loss: 0.1462 - acc: 0.9569 - val_loss: 0.1069 - val_acc: 0.9680\n",
      "Epoch 74/250\n",
      "48000/48000 [==============================] - 2s 41us/step - loss: 0.1439 - acc: 0.9583 - val_loss: 0.1067 - val_acc: 0.9683\n",
      "Epoch 75/250\n",
      "48000/48000 [==============================] - 2s 42us/step - loss: 0.1447 - acc: 0.9566 - val_loss: 0.1059 - val_acc: 0.9681\n",
      "Epoch 76/250\n",
      "48000/48000 [==============================] - 2s 41us/step - loss: 0.1414 - acc: 0.9580 - val_loss: 0.1059 - val_acc: 0.9685\n",
      "Epoch 77/250\n",
      "48000/48000 [==============================] - 2s 40us/step - loss: 0.1421 - acc: 0.9580 - val_loss: 0.1055 - val_acc: 0.9679\n",
      "Epoch 78/250\n",
      "48000/48000 [==============================] - 2s 41us/step - loss: 0.1399 - acc: 0.9588 - val_loss: 0.1044 - val_acc: 0.9691\n",
      "Epoch 79/250\n",
      "48000/48000 [==============================] - 2s 41us/step - loss: 0.1415 - acc: 0.9571 - val_loss: 0.1041 - val_acc: 0.9687\n",
      "Epoch 80/250\n",
      "48000/48000 [==============================] - 2s 40us/step - loss: 0.1393 - acc: 0.9595 - val_loss: 0.1033 - val_acc: 0.9688\n",
      "Epoch 81/250\n",
      "48000/48000 [==============================] - 2s 39us/step - loss: 0.1371 - acc: 0.9591 - val_loss: 0.1035 - val_acc: 0.9688\n",
      "Epoch 82/250\n",
      "48000/48000 [==============================] - 2s 40us/step - loss: 0.1366 - acc: 0.9580 - val_loss: 0.1031 - val_acc: 0.9687\n",
      "Epoch 83/250\n",
      "48000/48000 [==============================] - 2s 41us/step - loss: 0.1344 - acc: 0.9596 - val_loss: 0.1020 - val_acc: 0.9694\n",
      "Epoch 84/250\n",
      "48000/48000 [==============================] - 2s 40us/step - loss: 0.1338 - acc: 0.9600 - val_loss: 0.1014 - val_acc: 0.9693\n",
      "Epoch 85/250\n",
      "48000/48000 [==============================] - 2s 40us/step - loss: 0.1337 - acc: 0.9603 - val_loss: 0.1014 - val_acc: 0.9696\n",
      "Epoch 86/250\n",
      "48000/48000 [==============================] - 2s 40us/step - loss: 0.1346 - acc: 0.9602 - val_loss: 0.1006 - val_acc: 0.9698\n",
      "Epoch 87/250\n",
      "48000/48000 [==============================] - 2s 41us/step - loss: 0.1305 - acc: 0.9608 - val_loss: 0.1004 - val_acc: 0.9703\n",
      "Epoch 88/250\n",
      "48000/48000 [==============================] - 2s 40us/step - loss: 0.1321 - acc: 0.9595 - val_loss: 0.1000 - val_acc: 0.9697\n",
      "Epoch 89/250\n",
      "48000/48000 [==============================] - 2s 38us/step - loss: 0.1304 - acc: 0.9608 - val_loss: 0.0991 - val_acc: 0.9704\n",
      "Epoch 90/250\n",
      "48000/48000 [==============================] - 2s 41us/step - loss: 0.1321 - acc: 0.9604 - val_loss: 0.0987 - val_acc: 0.9703\n",
      "Epoch 91/250\n",
      "48000/48000 [==============================] - 2s 40us/step - loss: 0.1286 - acc: 0.9622 - val_loss: 0.0982 - val_acc: 0.9710\n",
      "Epoch 92/250\n",
      "48000/48000 [==============================] - 2s 43us/step - loss: 0.1318 - acc: 0.9601 - val_loss: 0.0986 - val_acc: 0.9715\n",
      "Epoch 93/250\n",
      "48000/48000 [==============================] - 2s 40us/step - loss: 0.1285 - acc: 0.9616 - val_loss: 0.0977 - val_acc: 0.9710\n",
      "Epoch 94/250\n",
      "48000/48000 [==============================] - 2s 39us/step - loss: 0.1250 - acc: 0.9622 - val_loss: 0.0975 - val_acc: 0.9711\n",
      "Epoch 95/250\n",
      "48000/48000 [==============================] - 2s 39us/step - loss: 0.1265 - acc: 0.9627 - val_loss: 0.0974 - val_acc: 0.9712\n",
      "Epoch 96/250\n",
      "48000/48000 [==============================] - 2s 40us/step - loss: 0.1239 - acc: 0.9625 - val_loss: 0.0969 - val_acc: 0.9716\n",
      "Epoch 97/250\n",
      "48000/48000 [==============================] - 2s 40us/step - loss: 0.1241 - acc: 0.9621 - val_loss: 0.0960 - val_acc: 0.9713\n",
      "Epoch 98/250\n",
      "48000/48000 [==============================] - 2s 40us/step - loss: 0.1235 - acc: 0.9630 - val_loss: 0.0965 - val_acc: 0.9716\n",
      "Epoch 99/250\n",
      "48000/48000 [==============================] - 2s 40us/step - loss: 0.1217 - acc: 0.9643 - val_loss: 0.0957 - val_acc: 0.9718\n",
      "Epoch 100/250\n",
      "48000/48000 [==============================] - 2s 40us/step - loss: 0.1211 - acc: 0.9636 - val_loss: 0.0957 - val_acc: 0.9722\n",
      "Epoch 101/250\n",
      "48000/48000 [==============================] - 2s 39us/step - loss: 0.1227 - acc: 0.9631 - val_loss: 0.0960 - val_acc: 0.9723\n",
      "Epoch 102/250\n",
      "48000/48000 [==============================] - 2s 38us/step - loss: 0.1215 - acc: 0.9640 - val_loss: 0.0947 - val_acc: 0.9722\n",
      "Epoch 103/250\n",
      "48000/48000 [==============================] - 2s 40us/step - loss: 0.1192 - acc: 0.9646 - val_loss: 0.0950 - val_acc: 0.9719\n",
      "Epoch 104/250\n",
      "48000/48000 [==============================] - 2s 41us/step - loss: 0.1177 - acc: 0.9647 - val_loss: 0.0942 - val_acc: 0.9722\n",
      "Epoch 105/250\n",
      "48000/48000 [==============================] - 2s 42us/step - loss: 0.1164 - acc: 0.9654 - val_loss: 0.0943 - val_acc: 0.9726\n",
      "Epoch 106/250\n",
      "48000/48000 [==============================] - 2s 39us/step - loss: 0.1170 - acc: 0.9649 - val_loss: 0.0939 - val_acc: 0.9725\n",
      "Epoch 107/250\n",
      "48000/48000 [==============================] - 2s 39us/step - loss: 0.1169 - acc: 0.9646 - val_loss: 0.0940 - val_acc: 0.9732\n",
      "Epoch 108/250\n",
      "48000/48000 [==============================] - 2s 46us/step - loss: 0.1139 - acc: 0.9666 - val_loss: 0.0933 - val_acc: 0.9722\n",
      "Epoch 109/250\n",
      "48000/48000 [==============================] - 2s 49us/step - loss: 0.1146 - acc: 0.9658 - val_loss: 0.0933 - val_acc: 0.9733\n",
      "Epoch 110/250\n",
      "48000/48000 [==============================] - 3s 67us/step - loss: 0.1141 - acc: 0.9660 - val_loss: 0.0928 - val_acc: 0.9727\n",
      "Epoch 111/250\n",
      "48000/48000 [==============================] - 3s 65us/step - loss: 0.1146 - acc: 0.9657 - val_loss: 0.0927 - val_acc: 0.9723\n",
      "Epoch 112/250\n",
      "48000/48000 [==============================] - 3s 70us/step - loss: 0.1117 - acc: 0.9660 - val_loss: 0.0918 - val_acc: 0.9738\n",
      "Epoch 113/250\n",
      "48000/48000 [==============================] - 3s 64us/step - loss: 0.1126 - acc: 0.9658 - val_loss: 0.0921 - val_acc: 0.9732\n",
      "Epoch 114/250\n",
      "48000/48000 [==============================] - 3s 64us/step - loss: 0.1144 - acc: 0.9655 - val_loss: 0.0915 - val_acc: 0.9736\n",
      "Epoch 115/250\n",
      "48000/48000 [==============================] - 3s 62us/step - loss: 0.1113 - acc: 0.9664 - val_loss: 0.0914 - val_acc: 0.9741\n",
      "Epoch 116/250\n",
      "48000/48000 [==============================] - 3s 62us/step - loss: 0.1087 - acc: 0.9673 - val_loss: 0.0911 - val_acc: 0.9737\n",
      "Epoch 117/250\n",
      "48000/48000 [==============================] - 3s 64us/step - loss: 0.1115 - acc: 0.9664 - val_loss: 0.0912 - val_acc: 0.9734\n",
      "Epoch 118/250\n",
      "48000/48000 [==============================] - 3s 61us/step - loss: 0.1087 - acc: 0.9670 - val_loss: 0.0908 - val_acc: 0.9738\n",
      "Epoch 119/250\n",
      "48000/48000 [==============================] - 5s 111us/step - loss: 0.1117 - acc: 0.9659 - val_loss: 0.0910 - val_acc: 0.9741\n",
      "Epoch 120/250\n",
      "48000/48000 [==============================] - 5s 98us/step - loss: 0.1070 - acc: 0.9676 - val_loss: 0.0901 - val_acc: 0.9745\n",
      "Epoch 121/250\n",
      "48000/48000 [==============================] - 4s 92us/step - loss: 0.1084 - acc: 0.9669 - val_loss: 0.0904 - val_acc: 0.9742\n",
      "Epoch 122/250\n",
      "48000/48000 [==============================] - 4s 86us/step - loss: 0.1074 - acc: 0.9673 - val_loss: 0.0895 - val_acc: 0.9744\n",
      "Epoch 123/250\n",
      "48000/48000 [==============================] - 4s 83us/step - loss: 0.1043 - acc: 0.9680 - val_loss: 0.0891 - val_acc: 0.9745\n",
      "Epoch 124/250\n",
      "48000/48000 [==============================] - 4s 87us/step - loss: 0.1047 - acc: 0.9683 - val_loss: 0.0894 - val_acc: 0.9745\n",
      "Epoch 125/250\n",
      "48000/48000 [==============================] - 4s 73us/step - loss: 0.1043 - acc: 0.9689 - val_loss: 0.0892 - val_acc: 0.9742\n",
      "Epoch 126/250\n",
      "48000/48000 [==============================] - 3s 70us/step - loss: 0.1035 - acc: 0.9685 - val_loss: 0.0888 - val_acc: 0.9745\n",
      "Epoch 127/250\n",
      "48000/48000 [==============================] - 3s 69us/step - loss: 0.1033 - acc: 0.9684 - val_loss: 0.0890 - val_acc: 0.9746\n",
      "Epoch 128/250\n",
      "48000/48000 [==============================] - 2s 50us/step - loss: 0.1043 - acc: 0.9686 - val_loss: 0.0884 - val_acc: 0.9751\n",
      "Epoch 129/250\n",
      "48000/48000 [==============================] - 2s 42us/step - loss: 0.1051 - acc: 0.9677 - val_loss: 0.0883 - val_acc: 0.9752\n",
      "Epoch 130/250\n",
      "48000/48000 [==============================] - 2s 42us/step - loss: 0.1039 - acc: 0.9689 - val_loss: 0.0883 - val_acc: 0.9752\n",
      "Epoch 131/250\n",
      "48000/48000 [==============================] - 2s 46us/step - loss: 0.1025 - acc: 0.9688 - val_loss: 0.0876 - val_acc: 0.9750\n",
      "Epoch 132/250\n",
      "48000/48000 [==============================] - 2s 49us/step - loss: 0.0999 - acc: 0.9703 - val_loss: 0.0880 - val_acc: 0.9752\n",
      "Epoch 133/250\n",
      "48000/48000 [==============================] - 2s 40us/step - loss: 0.1009 - acc: 0.9687 - val_loss: 0.0877 - val_acc: 0.9752\n",
      "Epoch 134/250\n",
      "48000/48000 [==============================] - 2s 36us/step - loss: 0.0989 - acc: 0.9687 - val_loss: 0.0877 - val_acc: 0.9747\n",
      "Epoch 135/250\n",
      "48000/48000 [==============================] - 2s 37us/step - loss: 0.1007 - acc: 0.9693 - val_loss: 0.0880 - val_acc: 0.9748\n",
      "Epoch 136/250\n",
      "48000/48000 [==============================] - 2s 37us/step - loss: 0.1001 - acc: 0.9705 - val_loss: 0.0876 - val_acc: 0.9752\n",
      "Epoch 137/250\n",
      "48000/48000 [==============================] - 2s 37us/step - loss: 0.0995 - acc: 0.9695 - val_loss: 0.0878 - val_acc: 0.9755\n",
      "Epoch 138/250\n",
      "48000/48000 [==============================] - 2s 36us/step - loss: 0.1003 - acc: 0.9689 - val_loss: 0.0875 - val_acc: 0.9755\n",
      "Epoch 139/250\n",
      "48000/48000 [==============================] - 2s 36us/step - loss: 0.0975 - acc: 0.9704 - val_loss: 0.0873 - val_acc: 0.9756\n",
      "Epoch 140/250\n",
      "48000/48000 [==============================] - 2s 36us/step - loss: 0.0964 - acc: 0.9709 - val_loss: 0.0869 - val_acc: 0.9756\n",
      "Epoch 141/250\n",
      "48000/48000 [==============================] - 2s 37us/step - loss: 0.0971 - acc: 0.9700 - val_loss: 0.0867 - val_acc: 0.9760\n",
      "Epoch 142/250\n",
      "48000/48000 [==============================] - 2s 36us/step - loss: 0.0952 - acc: 0.9707 - val_loss: 0.0864 - val_acc: 0.9761\n",
      "Epoch 143/250\n",
      "48000/48000 [==============================] - 2s 37us/step - loss: 0.0969 - acc: 0.9702 - val_loss: 0.0868 - val_acc: 0.9759\n",
      "Epoch 144/250\n",
      "48000/48000 [==============================] - 2s 36us/step - loss: 0.0945 - acc: 0.9712 - val_loss: 0.0864 - val_acc: 0.9759\n",
      "Epoch 145/250\n",
      "48000/48000 [==============================] - 2s 36us/step - loss: 0.0961 - acc: 0.9707 - val_loss: 0.0859 - val_acc: 0.9758\n",
      "Epoch 146/250\n",
      "48000/48000 [==============================] - 2s 36us/step - loss: 0.0939 - acc: 0.9720 - val_loss: 0.0863 - val_acc: 0.9754\n",
      "Epoch 147/250\n",
      "48000/48000 [==============================] - 2s 36us/step - loss: 0.0936 - acc: 0.9714 - val_loss: 0.0866 - val_acc: 0.9760\n",
      "Epoch 148/250\n",
      "48000/48000 [==============================] - 2s 36us/step - loss: 0.0948 - acc: 0.9708 - val_loss: 0.0861 - val_acc: 0.9760\n",
      "Epoch 149/250\n",
      "48000/48000 [==============================] - 2s 37us/step - loss: 0.0925 - acc: 0.9720 - val_loss: 0.0856 - val_acc: 0.9757\n",
      "Epoch 150/250\n",
      "48000/48000 [==============================] - 2s 36us/step - loss: 0.0916 - acc: 0.9720 - val_loss: 0.0863 - val_acc: 0.9758\n",
      "Epoch 151/250\n",
      "48000/48000 [==============================] - 2s 36us/step - loss: 0.0941 - acc: 0.9717 - val_loss: 0.0856 - val_acc: 0.9760\n",
      "Epoch 152/250\n",
      "48000/48000 [==============================] - 2s 36us/step - loss: 0.0923 - acc: 0.9723 - val_loss: 0.0852 - val_acc: 0.9763\n",
      "Epoch 153/250\n",
      "48000/48000 [==============================] - 2s 36us/step - loss: 0.0892 - acc: 0.9728 - val_loss: 0.0852 - val_acc: 0.9758\n",
      "Epoch 154/250\n",
      "48000/48000 [==============================] - 2s 37us/step - loss: 0.0916 - acc: 0.9725 - val_loss: 0.0854 - val_acc: 0.9759\n",
      "Epoch 155/250\n",
      "48000/48000 [==============================] - 2s 36us/step - loss: 0.0909 - acc: 0.9726 - val_loss: 0.0849 - val_acc: 0.9763\n",
      "Epoch 156/250\n",
      "48000/48000 [==============================] - 2s 37us/step - loss: 0.0910 - acc: 0.9727 - val_loss: 0.0848 - val_acc: 0.9759\n",
      "Epoch 157/250\n",
      "48000/48000 [==============================] - 2s 36us/step - loss: 0.0901 - acc: 0.9731 - val_loss: 0.0849 - val_acc: 0.9760\n",
      "Epoch 158/250\n",
      "48000/48000 [==============================] - 2s 38us/step - loss: 0.0886 - acc: 0.9732 - val_loss: 0.0854 - val_acc: 0.9761\n",
      "Epoch 159/250\n",
      "48000/48000 [==============================] - 2s 36us/step - loss: 0.0878 - acc: 0.9726 - val_loss: 0.0845 - val_acc: 0.9765\n",
      "Epoch 160/250\n",
      "48000/48000 [==============================] - 2s 43us/step - loss: 0.0893 - acc: 0.9728 - val_loss: 0.0848 - val_acc: 0.9761\n",
      "Epoch 161/250\n",
      "48000/48000 [==============================] - 2s 37us/step - loss: 0.0888 - acc: 0.9729 - val_loss: 0.0842 - val_acc: 0.9767\n",
      "Epoch 162/250\n",
      "48000/48000 [==============================] - 2s 39us/step - loss: 0.0885 - acc: 0.9736 - val_loss: 0.0842 - val_acc: 0.9764\n",
      "Epoch 163/250\n",
      "48000/48000 [==============================] - 2s 39us/step - loss: 0.0870 - acc: 0.9733 - val_loss: 0.0845 - val_acc: 0.9762\n",
      "Epoch 164/250\n",
      "48000/48000 [==============================] - 2s 39us/step - loss: 0.0878 - acc: 0.9730 - val_loss: 0.0841 - val_acc: 0.9767\n",
      "Epoch 165/250\n",
      "48000/48000 [==============================] - 2s 44us/step - loss: 0.0860 - acc: 0.9735 - val_loss: 0.0838 - val_acc: 0.9762\n",
      "Epoch 166/250\n",
      "48000/48000 [==============================] - 3s 62us/step - loss: 0.0862 - acc: 0.9732 - val_loss: 0.0847 - val_acc: 0.9762\n",
      "Epoch 167/250\n",
      "48000/48000 [==============================] - 3s 56us/step - loss: 0.0857 - acc: 0.9736 - val_loss: 0.0846 - val_acc: 0.9761\n",
      "Epoch 168/250\n",
      "48000/48000 [==============================] - 2s 37us/step - loss: 0.0837 - acc: 0.9747 - val_loss: 0.0843 - val_acc: 0.9760\n",
      "Epoch 169/250\n",
      "48000/48000 [==============================] - 2s 36us/step - loss: 0.0853 - acc: 0.9741 - val_loss: 0.0838 - val_acc: 0.9761\n",
      "Epoch 170/250\n",
      "48000/48000 [==============================] - 2s 36us/step - loss: 0.0871 - acc: 0.9735 - val_loss: 0.0834 - val_acc: 0.9762\n",
      "Epoch 171/250\n",
      "48000/48000 [==============================] - 2s 36us/step - loss: 0.0854 - acc: 0.9739 - val_loss: 0.0832 - val_acc: 0.9766\n",
      "Epoch 172/250\n",
      "48000/48000 [==============================] - 2s 36us/step - loss: 0.0845 - acc: 0.9738 - val_loss: 0.0833 - val_acc: 0.9760\n",
      "Epoch 173/250\n",
      "48000/48000 [==============================] - 2s 37us/step - loss: 0.0858 - acc: 0.9740 - val_loss: 0.0839 - val_acc: 0.9762\n",
      "Epoch 174/250\n",
      "48000/48000 [==============================] - 2s 36us/step - loss: 0.0826 - acc: 0.9748 - val_loss: 0.0832 - val_acc: 0.9762\n",
      "Epoch 175/250\n",
      "48000/48000 [==============================] - 2s 36us/step - loss: 0.0856 - acc: 0.9734 - val_loss: 0.0836 - val_acc: 0.9765\n",
      "Epoch 176/250\n",
      "48000/48000 [==============================] - 2s 37us/step - loss: 0.0807 - acc: 0.9753 - val_loss: 0.0837 - val_acc: 0.9766\n",
      "Epoch 177/250\n",
      "48000/48000 [==============================] - 2s 36us/step - loss: 0.0823 - acc: 0.9751 - val_loss: 0.0828 - val_acc: 0.9768\n",
      "Epoch 178/250\n",
      "48000/48000 [==============================] - 2s 36us/step - loss: 0.0825 - acc: 0.9746 - val_loss: 0.0827 - val_acc: 0.9770\n",
      "Epoch 179/250\n",
      "48000/48000 [==============================] - 2s 36us/step - loss: 0.0812 - acc: 0.9750 - val_loss: 0.0822 - val_acc: 0.9764\n",
      "Epoch 180/250\n",
      "48000/48000 [==============================] - 2s 36us/step - loss: 0.0835 - acc: 0.9740 - val_loss: 0.0830 - val_acc: 0.9767\n",
      "Epoch 181/250\n",
      "48000/48000 [==============================] - 2s 36us/step - loss: 0.0811 - acc: 0.9748 - val_loss: 0.0817 - val_acc: 0.9768\n",
      "Epoch 182/250\n",
      "48000/48000 [==============================] - 2s 37us/step - loss: 0.0784 - acc: 0.9756 - val_loss: 0.0826 - val_acc: 0.9770\n",
      "Epoch 183/250\n",
      "48000/48000 [==============================] - 2s 36us/step - loss: 0.0803 - acc: 0.9758 - val_loss: 0.0823 - val_acc: 0.9768\n",
      "Epoch 184/250\n",
      "48000/48000 [==============================] - 2s 36us/step - loss: 0.0808 - acc: 0.9751 - val_loss: 0.0818 - val_acc: 0.9767\n",
      "Epoch 185/250\n",
      "48000/48000 [==============================] - 2s 36us/step - loss: 0.0792 - acc: 0.9755 - val_loss: 0.0821 - val_acc: 0.9766\n",
      "Epoch 186/250\n",
      "48000/48000 [==============================] - 2s 36us/step - loss: 0.0807 - acc: 0.9755 - val_loss: 0.0824 - val_acc: 0.9768\n",
      "Epoch 187/250\n",
      "48000/48000 [==============================] - 2s 36us/step - loss: 0.0785 - acc: 0.9755 - val_loss: 0.0820 - val_acc: 0.9762\n",
      "Epoch 188/250\n",
      "48000/48000 [==============================] - 2s 36us/step - loss: 0.0795 - acc: 0.9753 - val_loss: 0.0812 - val_acc: 0.9767\n",
      "Epoch 189/250\n",
      "48000/48000 [==============================] - 2s 36us/step - loss: 0.0775 - acc: 0.9759 - val_loss: 0.0820 - val_acc: 0.9767\n",
      "Epoch 190/250\n",
      "48000/48000 [==============================] - 2s 37us/step - loss: 0.0775 - acc: 0.9759 - val_loss: 0.0821 - val_acc: 0.9767\n",
      "Epoch 191/250\n",
      "48000/48000 [==============================] - 2s 37us/step - loss: 0.0780 - acc: 0.9767 - val_loss: 0.0821 - val_acc: 0.9768\n",
      "Epoch 192/250\n",
      "48000/48000 [==============================] - 2s 36us/step - loss: 0.0797 - acc: 0.9759 - val_loss: 0.0820 - val_acc: 0.9771\n",
      "Epoch 193/250\n",
      "48000/48000 [==============================] - 2s 36us/step - loss: 0.0775 - acc: 0.9762 - val_loss: 0.0818 - val_acc: 0.9770\n",
      "Epoch 194/250\n",
      "48000/48000 [==============================] - 2s 37us/step - loss: 0.0780 - acc: 0.9763 - val_loss: 0.0818 - val_acc: 0.9769\n",
      "Epoch 195/250\n",
      "48000/48000 [==============================] - 2s 37us/step - loss: 0.0768 - acc: 0.9763 - val_loss: 0.0820 - val_acc: 0.9765\n",
      "Epoch 196/250\n",
      "48000/48000 [==============================] - 2s 36us/step - loss: 0.0742 - acc: 0.9771 - val_loss: 0.0817 - val_acc: 0.9766\n",
      "Epoch 197/250\n",
      "48000/48000 [==============================] - 2s 36us/step - loss: 0.0769 - acc: 0.9758 - val_loss: 0.0816 - val_acc: 0.9768\n",
      "Epoch 198/250\n",
      "48000/48000 [==============================] - 2s 36us/step - loss: 0.0749 - acc: 0.9768 - val_loss: 0.0814 - val_acc: 0.9768\n",
      "Epoch 199/250\n",
      "48000/48000 [==============================] - 2s 37us/step - loss: 0.0750 - acc: 0.9770 - val_loss: 0.0810 - val_acc: 0.9772\n",
      "Epoch 200/250\n",
      "48000/48000 [==============================] - 2s 36us/step - loss: 0.0742 - acc: 0.9768 - val_loss: 0.0809 - val_acc: 0.9765\n",
      "Epoch 201/250\n",
      "48000/48000 [==============================] - 2s 36us/step - loss: 0.0746 - acc: 0.9764 - val_loss: 0.0814 - val_acc: 0.9768\n",
      "Epoch 202/250\n",
      "48000/48000 [==============================] - 2s 36us/step - loss: 0.0781 - acc: 0.9762 - val_loss: 0.0810 - val_acc: 0.9775\n",
      "Epoch 203/250\n",
      "48000/48000 [==============================] - 2s 36us/step - loss: 0.0749 - acc: 0.9771 - val_loss: 0.0810 - val_acc: 0.9767\n",
      "Epoch 204/250\n",
      "48000/48000 [==============================] - 2s 36us/step - loss: 0.0719 - acc: 0.9773 - val_loss: 0.0810 - val_acc: 0.9770\n",
      "Epoch 205/250\n",
      "48000/48000 [==============================] - 2s 36us/step - loss: 0.0753 - acc: 0.9767 - val_loss: 0.0813 - val_acc: 0.9768\n",
      "Epoch 206/250\n",
      "48000/48000 [==============================] - 2s 36us/step - loss: 0.0731 - acc: 0.9774 - val_loss: 0.0813 - val_acc: 0.9772\n",
      "Epoch 207/250\n",
      "48000/48000 [==============================] - 2s 36us/step - loss: 0.0724 - acc: 0.9771 - val_loss: 0.0811 - val_acc: 0.9762\n",
      "Epoch 208/250\n",
      "48000/48000 [==============================] - 2s 36us/step - loss: 0.0725 - acc: 0.9772 - val_loss: 0.0814 - val_acc: 0.9770\n",
      "Epoch 209/250\n",
      "48000/48000 [==============================] - 2s 36us/step - loss: 0.0731 - acc: 0.9775 - val_loss: 0.0813 - val_acc: 0.9767\n",
      "Epoch 210/250\n",
      "48000/48000 [==============================] - 2s 36us/step - loss: 0.0710 - acc: 0.9778 - val_loss: 0.0815 - val_acc: 0.9770\n",
      "Epoch 211/250\n",
      "48000/48000 [==============================] - 2s 36us/step - loss: 0.0733 - acc: 0.9764 - val_loss: 0.0819 - val_acc: 0.9771\n",
      "Epoch 212/250\n",
      "48000/48000 [==============================] - 2s 36us/step - loss: 0.0739 - acc: 0.9770 - val_loss: 0.0815 - val_acc: 0.9767\n",
      "Epoch 213/250\n",
      "48000/48000 [==============================] - 2s 36us/step - loss: 0.0724 - acc: 0.9778 - val_loss: 0.0808 - val_acc: 0.9774\n",
      "Epoch 214/250\n",
      "48000/48000 [==============================] - 2s 36us/step - loss: 0.0721 - acc: 0.9781 - val_loss: 0.0810 - val_acc: 0.9774\n",
      "Epoch 215/250\n",
      "48000/48000 [==============================] - 2s 36us/step - loss: 0.0706 - acc: 0.9784 - val_loss: 0.0808 - val_acc: 0.9772\n",
      "Epoch 216/250\n",
      "48000/48000 [==============================] - 2s 37us/step - loss: 0.0708 - acc: 0.9776 - val_loss: 0.0808 - val_acc: 0.9773\n",
      "Epoch 217/250\n",
      "48000/48000 [==============================] - 2s 36us/step - loss: 0.0707 - acc: 0.9783 - val_loss: 0.0806 - val_acc: 0.9772\n",
      "Epoch 218/250\n",
      "48000/48000 [==============================] - 2s 36us/step - loss: 0.0687 - acc: 0.9785 - val_loss: 0.0810 - val_acc: 0.9770\n",
      "Epoch 219/250\n",
      "48000/48000 [==============================] - 2s 36us/step - loss: 0.0707 - acc: 0.9781 - val_loss: 0.0802 - val_acc: 0.9770\n",
      "Epoch 220/250\n",
      "48000/48000 [==============================] - 2s 36us/step - loss: 0.0689 - acc: 0.9789 - val_loss: 0.0803 - val_acc: 0.9771\n",
      "Epoch 221/250\n",
      "48000/48000 [==============================] - 2s 36us/step - loss: 0.0705 - acc: 0.9779 - val_loss: 0.0811 - val_acc: 0.9769\n",
      "Epoch 222/250\n",
      "48000/48000 [==============================] - 2s 36us/step - loss: 0.0687 - acc: 0.9788 - val_loss: 0.0808 - val_acc: 0.9767\n",
      "Epoch 223/250\n",
      "48000/48000 [==============================] - 2s 36us/step - loss: 0.0707 - acc: 0.9773 - val_loss: 0.0806 - val_acc: 0.9771\n",
      "Epoch 224/250\n",
      "48000/48000 [==============================] - 2s 36us/step - loss: 0.0699 - acc: 0.9791 - val_loss: 0.0804 - val_acc: 0.9774\n",
      "Epoch 225/250\n",
      "48000/48000 [==============================] - 2s 37us/step - loss: 0.0673 - acc: 0.9790 - val_loss: 0.0806 - val_acc: 0.9776\n",
      "Epoch 226/250\n",
      "48000/48000 [==============================] - 2s 37us/step - loss: 0.0684 - acc: 0.9789 - val_loss: 0.0804 - val_acc: 0.9771\n",
      "Epoch 227/250\n",
      "48000/48000 [==============================] - 2s 36us/step - loss: 0.0667 - acc: 0.9792 - val_loss: 0.0807 - val_acc: 0.9772\n",
      "Epoch 228/250\n",
      "48000/48000 [==============================] - 2s 37us/step - loss: 0.0693 - acc: 0.9787 - val_loss: 0.0806 - val_acc: 0.9769\n",
      "Epoch 229/250\n",
      "48000/48000 [==============================] - 2s 37us/step - loss: 0.0687 - acc: 0.9785 - val_loss: 0.0806 - val_acc: 0.9770\n",
      "Epoch 230/250\n",
      "48000/48000 [==============================] - 2s 37us/step - loss: 0.0684 - acc: 0.9786 - val_loss: 0.0801 - val_acc: 0.9768\n",
      "Epoch 231/250\n",
      "48000/48000 [==============================] - 2s 36us/step - loss: 0.0671 - acc: 0.9795 - val_loss: 0.0799 - val_acc: 0.9773\n",
      "Epoch 232/250\n",
      "48000/48000 [==============================] - 2s 36us/step - loss: 0.0680 - acc: 0.9788 - val_loss: 0.0801 - val_acc: 0.9771\n",
      "Epoch 233/250\n",
      "48000/48000 [==============================] - 2s 36us/step - loss: 0.0648 - acc: 0.9796 - val_loss: 0.0806 - val_acc: 0.9774\n",
      "Epoch 234/250\n",
      "48000/48000 [==============================] - 2s 37us/step - loss: 0.0678 - acc: 0.9782 - val_loss: 0.0803 - val_acc: 0.9777\n",
      "Epoch 235/250\n",
      "48000/48000 [==============================] - 2s 36us/step - loss: 0.0664 - acc: 0.9793 - val_loss: 0.0795 - val_acc: 0.9773\n",
      "Epoch 236/250\n",
      "48000/48000 [==============================] - 2s 36us/step - loss: 0.0686 - acc: 0.9785 - val_loss: 0.0795 - val_acc: 0.9772\n",
      "Epoch 237/250\n",
      "48000/48000 [==============================] - 2s 36us/step - loss: 0.0650 - acc: 0.9796 - val_loss: 0.0801 - val_acc: 0.9777\n",
      "Epoch 238/250\n",
      "48000/48000 [==============================] - 2s 36us/step - loss: 0.0664 - acc: 0.9792 - val_loss: 0.0804 - val_acc: 0.9776\n",
      "Epoch 239/250\n",
      "48000/48000 [==============================] - 2s 36us/step - loss: 0.0669 - acc: 0.9793 - val_loss: 0.0807 - val_acc: 0.9775\n",
      "Epoch 240/250\n",
      "48000/48000 [==============================] - 2s 36us/step - loss: 0.0688 - acc: 0.9787 - val_loss: 0.0803 - val_acc: 0.9775\n",
      "Epoch 241/250\n",
      "48000/48000 [==============================] - 2s 36us/step - loss: 0.0648 - acc: 0.9798 - val_loss: 0.0806 - val_acc: 0.9773\n",
      "Epoch 242/250\n",
      "48000/48000 [==============================] - 2s 37us/step - loss: 0.0656 - acc: 0.9789 - val_loss: 0.0798 - val_acc: 0.9777\n",
      "Epoch 243/250\n",
      "48000/48000 [==============================] - 2s 36us/step - loss: 0.0658 - acc: 0.9792 - val_loss: 0.0796 - val_acc: 0.9776\n",
      "Epoch 244/250\n",
      "48000/48000 [==============================] - 2s 36us/step - loss: 0.0656 - acc: 0.9797 - val_loss: 0.0798 - val_acc: 0.9774\n",
      "Epoch 245/250\n",
      "48000/48000 [==============================] - 2s 36us/step - loss: 0.0634 - acc: 0.9805 - val_loss: 0.0799 - val_acc: 0.9772\n",
      "Epoch 246/250\n",
      "48000/48000 [==============================] - 2s 36us/step - loss: 0.0628 - acc: 0.9804 - val_loss: 0.0810 - val_acc: 0.9770\n",
      "Epoch 247/250\n",
      "48000/48000 [==============================] - 2s 38us/step - loss: 0.0621 - acc: 0.9803 - val_loss: 0.0801 - val_acc: 0.9775\n",
      "Epoch 248/250\n",
      "48000/48000 [==============================] - 2s 36us/step - loss: 0.0632 - acc: 0.9805 - val_loss: 0.0802 - val_acc: 0.9770\n",
      "Epoch 249/250\n",
      "48000/48000 [==============================] - 2s 36us/step - loss: 0.0636 - acc: 0.9799 - val_loss: 0.0804 - val_acc: 0.9777\n",
      "Epoch 250/250\n",
      "48000/48000 [==============================] - 2s 36us/step - loss: 0.0616 - acc: 0.9808 - val_loss: 0.0801 - val_acc: 0.9777\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, Y_train, batch_size=BATCH_SIZE, epochs=NB_EPOCH, verbose=VERBOSE, validation_split=VALIDATION_SPLIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 26us/step\n",
      "Test score:  0.07736443599500926\n",
      "Test accuracy:  0.9781\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test, verbose=VERBOSE)\n",
    "print(\"Test score: \", score[0])\n",
    "print(\"Test accuracy: \", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(*args, **kw)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 히스토리의 모든 데이터 목록\n",
    "print(history.history.keys())\n",
    "# 정확도 히스토리를 요약\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(*args, **kw)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 손실 히스토리를 요약\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
